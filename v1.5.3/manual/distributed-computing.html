<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>複数プロセス処理と分散計算 · The Julia Language</title><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-28835595-6', 'auto');
ga('send', 'pageview', {'page': location.pathname + location.search + location.hash});
</script><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/julia-manual.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../index.html"><img class="docs-light-only" src="../assets/logo.svg" alt="The Julia Language logo"/><img class="docs-dark-only" src="../assets/logo-dark.svg" alt="The Julia Language logo"/></a><form class="docs-search" action="../search.html"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../index.html">Julia Documentation</a></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox" checked/><label class="tocitem" for="menuitem-3"><span class="docs-label">Manual</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="getting-started.html">Getting Started</a></li><li><a class="tocitem" href="variables.html">Variables</a></li><li><a class="tocitem" href="integers-and-floating-point-numbers.html">整数と浮動小数点数</a></li><li><a class="tocitem" href="mathematical-operations.html">Mathematical Operations and Elementary Functions</a></li><li><a class="tocitem" href="complex-and-rational-numbers.html">複素数と有理数</a></li><li><a class="tocitem" href="strings.html">Strings</a></li><li><a class="tocitem" href="functions.html">Functions</a></li><li><a class="tocitem" href="control-flow.html">Control Flow</a></li><li><a class="tocitem" href="variables-and-scoping.html">Scope of Variables</a></li><li><a class="tocitem" href="types.html">Types</a></li><li><a class="tocitem" href="methods.html">Methods</a></li><li><a class="tocitem" href="constructors.html">Constructors</a></li><li><a class="tocitem" href="conversion-and-promotion.html">Conversion and Promotion</a></li><li><a class="tocitem" href="interfaces.html">Interfaces</a></li><li><a class="tocitem" href="modules.html">Modules</a></li><li><a class="tocitem" href="documentation.html">Documentation</a></li><li><a class="tocitem" href="metaprogramming.html">Metaprogramming</a></li><li><a class="tocitem" href="arrays.html">Multi-dimensional Arrays</a></li><li><a class="tocitem" href="missing.html">Missing Values</a></li><li><a class="tocitem" href="networking-and-streams.html">Networking and Streams</a></li><li><a class="tocitem" href="parallel-computing.html">並列計算</a></li><li><a class="tocitem" href="asynchronous-programming.html">非同期プログラミング</a></li><li><a class="tocitem" href="multi-threading.html">Multi-Threading</a></li><li class="is-active"><a class="tocitem" href="distributed-computing.html">複数プロセス処理と分散計算</a><ul class="internal"><li><a class="tocitem" href="#code-availability"><span>コードの利用可能性とパッケージの読み込み</span></a></li><li><a class="tocitem" href="#ワーカプロセスの開始と管理"><span>ワーカプロセスの開始と管理</span></a></li><li><a class="tocitem" href="#データ移動"><span>データ移動</span></a></li><li><a class="tocitem" href="#グローバル変数"><span>グローバル変数</span></a></li><li><a class="tocitem" href="#並列マップとループ"><span>並列マップとループ</span></a></li><li><a class="tocitem" href="#リモートリファレンスとアブストラクトチャネル"><span>リモートリファレンスとアブストラクトチャネル</span></a></li><li><a class="tocitem" href="#チャネルとリモートチャネル"><span>チャネルとリモートチャネル</span></a></li><li><a class="tocitem" href="#ローカルな呼び出し"><span>ローカルな呼び出し</span></a></li><li><a class="tocitem" href="#man-shared-arrays"><span>Shared Arrays</span></a></li><li><a class="tocitem" href="#ClusterManagers"><span>ClusterManagers</span></a></li><li><a class="tocitem" href="#ネットワークトポロジの指定-(Experimental)"><span>ネットワークトポロジの指定 (Experimental)</span></a></li><li><a class="tocitem" href="#注目すべき外部パッケージ"><span>注目すべき外部パッケージ</span></a></li></ul></li><li><a class="tocitem" href="running-external-programs.html">外部プログラムの実行</a></li><li><a class="tocitem" href="calling-c-and-fortran-code.html">Calling C and Fortran Code</a></li><li><a class="tocitem" href="handling-operating-system-variation.html">OSの違いへの対応</a></li><li><a class="tocitem" href="environment-variables.html">Environment Variables</a></li><li><a class="tocitem" href="embedding.html">Embedding Julia</a></li><li><a class="tocitem" href="code-loading.html">コードの読み込み</a></li><li><a class="tocitem" href="profile.html">プロファイリング</a></li><li><a class="tocitem" href="stacktraces.html">Stack Traces</a></li><li><a class="tocitem" href="performance-tips.html">パフォーマンスのヒント</a></li><li><a class="tocitem" href="workflow-tips.html">Workflow Tips</a></li><li><a class="tocitem" href="style-guide.html">Style Guide</a></li><li><a class="tocitem" href="faq.html">Frequently Asked Questions</a></li><li><a class="tocitem" href="noteworthy-differences.html">Noteworthy Differences from other Languages</a></li><li><a class="tocitem" href="unicode-input.html">Unicode Input</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">Base</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../base/base.html">Essentials</a></li><li><a class="tocitem" href="../base/collections.html">Collections and Data Structures</a></li><li><a class="tocitem" href="../base/math.html">Mathematics</a></li><li><a class="tocitem" href="../base/numbers.html">Numbers</a></li><li><a class="tocitem" href="../base/strings.html">Strings</a></li><li><a class="tocitem" href="../base/arrays.html">Arrays</a></li><li><a class="tocitem" href="../base/parallel.html">Tasks</a></li><li><a class="tocitem" href="../base/multi-threading.html">Multi-Threading</a></li><li><a class="tocitem" href="../base/constants.html">Constants</a></li><li><a class="tocitem" href="../base/file.html">Filesystem</a></li><li><a class="tocitem" href="../base/io-network.html">I/O and Network</a></li><li><a class="tocitem" href="../base/punctuation.html">Punctuation</a></li><li><a class="tocitem" href="../base/sort.html">Sorting and Related Functions</a></li><li><a class="tocitem" href="../base/iterators.html">Iteration utilities</a></li><li><a class="tocitem" href="../base/c.html">C Interface</a></li><li><a class="tocitem" href="../base/libc.html">C Standard Library</a></li><li><a class="tocitem" href="../base/stacktraces.html">StackTraces</a></li><li><a class="tocitem" href="../base/simd-types.html">SIMD Support</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5" type="checkbox"/><label class="tocitem" for="menuitem-5"><span class="docs-label">Standard Library</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../stdlib/Base64.html">Base64</a></li><li><a class="tocitem" href="../stdlib/CRC32c.html">CRC32c</a></li><li><a class="tocitem" href="../stdlib/Dates.html">Dates</a></li><li><a class="tocitem" href="../stdlib/DelimitedFiles.html">Delimited Files</a></li><li><a class="tocitem" href="../stdlib/Distributed.html">Distributed Computing</a></li><li><a class="tocitem" href="../stdlib/FileWatching.html">File Events</a></li><li><a class="tocitem" href="../stdlib/Future.html">Future</a></li><li><a class="tocitem" href="../stdlib/InteractiveUtils.html">Interactive Utilities</a></li><li><a class="tocitem" href="../stdlib/LibGit2.html">LibGit2</a></li><li><a class="tocitem" href="../stdlib/Libdl.html">Dynamic Linker</a></li><li><a class="tocitem" href="../stdlib/LinearAlgebra.html">Linear Algebra</a></li><li><a class="tocitem" href="../stdlib/Logging.html">Logging</a></li><li><a class="tocitem" href="../stdlib/Markdown.html">Markdown</a></li><li><a class="tocitem" href="../stdlib/Mmap.html">Memory-mapped I/O</a></li><li><a class="tocitem" href="../stdlib/Pkg.html">Pkg</a></li><li><a class="tocitem" href="../stdlib/Printf.html">Printf</a></li><li><a class="tocitem" href="../stdlib/Profile.html">Profiling</a></li><li><a class="tocitem" href="../stdlib/REPL.html">The Julia REPL</a></li><li><a class="tocitem" href="../stdlib/Random.html">Random Numbers</a></li><li><a class="tocitem" href="../stdlib/SHA.html">SHA</a></li><li><a class="tocitem" href="../stdlib/Serialization.html">Serialization</a></li><li><a class="tocitem" href="../stdlib/SharedArrays.html">Shared Arrays</a></li><li><a class="tocitem" href="../stdlib/Sockets.html">Sockets</a></li><li><a class="tocitem" href="../stdlib/SparseArrays.html">Sparse Arrays</a></li><li><a class="tocitem" href="../stdlib/Statistics.html">Statistics</a></li><li><a class="tocitem" href="../stdlib/Test.html">Unit Testing</a></li><li><a class="tocitem" href="../stdlib/UUIDs.html">UUIDs</a></li><li><a class="tocitem" href="../stdlib/Unicode.html">Unicode</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-6" type="checkbox"/><label class="tocitem" for="menuitem-6"><span class="docs-label">Developer Documentation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../devdocs/reflection.html">Reflection and introspection</a></li><li><input class="collapse-toggle" id="menuitem-6-2" type="checkbox"/><label class="tocitem" for="menuitem-6-2"><span class="docs-label">Documentation of Julia&#39;s Internals</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../devdocs/init.html">Initialization of the Julia runtime</a></li><li><a class="tocitem" href="../devdocs/ast.html">Julia ASTs</a></li><li><a class="tocitem" href="../devdocs/types.html">More about types</a></li><li><a class="tocitem" href="../devdocs/object.html">Memory layout of Julia Objects</a></li><li><a class="tocitem" href="../devdocs/eval.html">Eval of Julia code</a></li><li><a class="tocitem" href="../devdocs/callconv.html">Calling Conventions</a></li><li><a class="tocitem" href="../devdocs/compiler.html">High-level Overview of the Native-Code Generation Process</a></li><li><a class="tocitem" href="../devdocs/functions.html">Julia Functions</a></li><li><a class="tocitem" href="../devdocs/cartesian.html">Base.Cartesian</a></li><li><a class="tocitem" href="../devdocs/meta.html">Talking to the compiler (the <code>:meta</code> mechanism)</a></li><li><a class="tocitem" href="../devdocs/subarrays.html">SubArrays</a></li><li><a class="tocitem" href="../devdocs/isbitsunionarrays.html">isbits Union Optimizations</a></li><li><a class="tocitem" href="../devdocs/sysimg.html">System Image Building</a></li><li><a class="tocitem" href="../devdocs/llvm.html">Working with LLVM</a></li><li><a class="tocitem" href="../devdocs/stdio.html">printf() and stdio in the Julia runtime</a></li><li><a class="tocitem" href="../devdocs/boundscheck.html">Bounds checking</a></li><li><a class="tocitem" href="../devdocs/locks.html">Proper maintenance and care of multi-threading locks</a></li><li><a class="tocitem" href="../devdocs/offset-arrays.html">Arrays with custom indices</a></li><li><a class="tocitem" href="../devdocs/require.html">Module loading</a></li><li><a class="tocitem" href="../devdocs/inference.html">Inference</a></li><li><a class="tocitem" href="../devdocs/ssair.html">Julia SSA-form IR</a></li><li><a class="tocitem" href="../devdocs/gc-sa.html">Static analyzer annotations for GC correctness in C code</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-6-3" type="checkbox"/><label class="tocitem" for="menuitem-6-3"><span class="docs-label">Developing/debugging Julia&#39;s C code</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../devdocs/backtraces.html">Reporting and analyzing crashes (segfaults)</a></li><li><a class="tocitem" href="../devdocs/debuggingtips.html">gdb debugging tips</a></li><li><a class="tocitem" href="../devdocs/valgrind.html">Using Valgrind with Julia</a></li><li><a class="tocitem" href="../devdocs/sanitizers.html">Sanitizer support</a></li></ul></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Manual</a></li><li class="is-active"><a href="distributed-computing.html">複数プロセス処理と分散計算</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="distributed-computing.html">複数プロセス処理と分散計算</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/fms-lab/julia-doc-ja/blob/main/doc/src/manual/distributed-computing.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="複数プロセス処理と分散計算"><a class="docs-heading-anchor" href="#複数プロセス処理と分散計算">複数プロセス処理と分散計算</a><a id="複数プロセス処理と分散計算-1"></a><a class="docs-heading-anchor-permalink" href="#複数プロセス処理と分散計算" title="Permalink"></a></h1><p>分散メモリ型の並列計算の実装は，Julia同梱の標準ライブラリの一部として<code>Distributed</code>モジュールによって提供されます．</p><p>ほとんどの現代の計算機は2つ以上のCPUを搭載しており，クラスタ内で複数の計算機をまとめて用いることができます． これらの複数CPUの力を使いこなすことで，より多くの計算をより高速に行うことが可能となります． 性能に影響を及ぼすのは2つの大きな要因があります: CPUのスピードそのものと，CPUがメモリへアクセスする速度です． クラスタにおいては，ある特定のCPUが同じコンピュータ（ノード）内のRAMに最速でアクセスできることはほぼ自明です． おそらくもっと驚くべきことに，メインメモリと<a href="https://www.akkadia.org/drepper/cpumemory.pdf">キャッシュ</a>の速度 が異なることが原因で，同様の問題が一般的なマルチコアラップトップにも関連してきます． したがって，優れたマルチプロセシング環境では，特定のCPUによってメモリチャンクの「所有権」を制御できるべきです． Juliaはメッセージパッシングに基づいてマルチプロセシング環境を提供し，別々のメモリドメイン内の複数プロセス上で プログラムを一度に実行することを可能にします．</p><p>Juliaのメッセージパッシングの実装は，MPI<sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup>などほかの環境とは異なるものとなっています． Julia内の通信は一般的には「一方向的(one-sided)」です，すなわちプログラマは2プロセスの操作の内，1つのプロセス のみを明示的に管理する必要があります．さらには，これらの操作は典型的には「メッセージ送信」や「メッセージ受信」 のようには見えず，ユーザ関数を呼び出すような高レベルな操作に似たものとなります．</p><p>Juliaにおける分散計算は，2つのプリミティブによって構成されます: <em>リモートリファレンス</em>と<em>リモートコール</em>です． リモートリファレンスは，任意のプロセスから，特定のプロセスに格納されているオブジェクトを参照するために使うことができるものです．リモートコールは1つのプロセスによるリクエストで，別の（同じでも良い）プロセス上で関数と引数を指定しながら呼び出すためのものです．</p><p>リモートリファレンスには2つのフレーバーがあります: <a href="../stdlib/Distributed.html#Distributed.Future"><code>Future</code></a> and <a href="../stdlib/Distributed.html#Distributed.RemoteChannel"><code>RemoteChannel</code></a>です．</p><p>リモートコールは，<a href="../stdlib/Distributed.html#Distributed.Future"><code>Future</code></a>をその結果に返します．リモートコールは直ちに結果を返します， すなわちリモート呼び出しが別の場所で発生している間に，呼び出しを行ったプロセスは次の操作に進みます． あなたはリモートコールが終わるのを<a href="../base/parallel.html#Base.wait"><code>wait</code></a>を返される<a href="../stdlib/Distributed.html#Distributed.Future"><code>Future</code></a>上で呼ぶことで待つことができ， また<a href="../base/parallel.html#Base.fetch-Tuple{Task}"><code>fetch</code></a>を用いて結果のすべての値を取得することができます．</p><p>一方で，<a href="../stdlib/Distributed.html#Distributed.RemoteChannel"><code>RemoteChannel</code></a>は上書き可能です．例えば，複数のプロセスが同じリモートの<code>Channel</code>を参照することにより それらの処理を組み合わせることができます．</p><p>各プロセスは識別子を持ちます．インタラクティブなJuliaプロンプトを提供するプロセスは常に1という<code>id</code>を持ちます． 並列操作に用いられるプロセスはデフォルトでは「ワーカ」として参照されます．プロセスが一つだけの時は，プロセス1が ワーカとしてとらえられます．そうでない場合は，ワーカはプロセス1以外のすべてのプロセスであるととらえられます． 結果として，<a href="../stdlib/Distributed.html#Distributed.pmap"><code>pmap</code></a>のような並列処理メソッドから恩恵を得るためには，2つ以上のプロセスが必要となります． 長い計算がワーカ上で実行されている間にメインプロセスで他のことをやらせたい場合は，シングルプロセスを1つ足すことで恩恵を得られます．</p><p>これを試してみましょう．<code>julia -p n</code>で始めると，<code>n</code>はローカルマシン上にn個のワーカプロセスを提供します． 一般的に<code>n</code>はマシン上のCPUスレッド数（論理コア数）と同じにするのが理にかなっています．<code>-p</code>引数は，暗黙の内に <code>Distributed</code>モジュールをロードすることに注意してください．</p><pre><code class="language-julia">$ ./julia -p 2

julia&gt; r = remotecall(rand, 2, 2, 2)
Future(2, 1, 4, nothing)

julia&gt; s = @spawnat 2 1 .+ fetch(r)
Future(2, 1, 5, nothing)

julia&gt; fetch(s)
2×2 Array{Float64,2}:
 1.18526  1.50912
 1.16296  1.60607</code></pre><p><a href="../stdlib/Distributed.html#Distributed.remotecall-Tuple{Any,Integer,Vararg{Any,N} where N}"><code>remotecall</code></a>の第一引数は呼び出される関数です．Juliaにおける並列プログラミングのほとんどは， 特定のプロセスや利用可能なプロセス数を参照しませんが，<a href="../stdlib/Distributed.html#Distributed.remotecall-Tuple{Any,Integer,Vararg{Any,N} where N}"><code>remotecall</code></a>はより細かい制御を 提供する低レベルのインタフェースと考えられています．<a href="../stdlib/Distributed.html#Distributed.remotecall-Tuple{Any,Integer,Vararg{Any,N} where N}"><code>remotecall</code></a>の第二引数は処理を行う プロセスの<code>id</code>で，残りの引数は呼び出される関数に渡されます．</p><p>1行目ではプロセス2に2x2のランダム行列を構築するように求め，2行目ではこれに1を加えるように求めていることが 見て取れます．両方の計算結果は，2つのフューチャ，<code>r</code>と<code>s</code>で利用可能です．<a href="../stdlib/Distributed.html#Distributed.@spawnat"><code>@spawnat</code></a>マクロは， 第一引数で指定されたプロセス上で第二引数内の表現を評価します．</p><p>リモートで計算された値がすぐに必要になることがあるかもしれません．これは典型的には，次のローカル操作で必要な データを取得するために，リモートオブジェクトから読み出しを行う時に起こります．この目的のために，<a href="../stdlib/Distributed.html#Distributed.remotecall_fetch-Tuple{Any,Integer,Vararg{Any,N} where N}"><code>remotecall_fetch</code></a> 関数が存在します．これは<code>fetch(remotecall(...))</code>と等価ですが，より効率的です．</p><pre><code class="language-julia-repl">julia&gt; remotecall_fetch(getindex, 2, r, 1, 1)
0.18526337335308085</code></pre><p><a href="../base/arrays.html#Base.getindex-Tuple{Type,Vararg{Any,N} where N}"><code>getindex(r,1,1)</code></a>は<code>r[1,1]</code>と<a href="arrays.html#man-array-indexing">equivalent</a>であるため，この呼び出しはフューチャ<code>r</code>の 最初の要素をフェッチすることを覚えておいてください．</p><p>より簡単にするために，シンボル<code>:any</code>を[<code>@spawnat</code>]に渡すことができ，これにより操作を行う場所を選択します．</p><pre><code class="language-julia-repl">julia&gt; r = @spawnat :any rand(2,2)
Future(2, 1, 4, nothing)

julia&gt; s = @spawnat :any 1 .+ fetch(r)
Future(3, 1, 5, nothing)

julia&gt; fetch(s)
2×2 Array{Float64,2}:
 1.38854  1.9098
 1.20939  1.57158</code></pre><p>ここで，私たちが<code>1 .+ r</code>ではなく，<code>1 .+ fetch(r)</code>を用いていることに注意してください．これはコードがどこで 実行されるのかを知ることができないため，一般的には，加算を行うプロセスに<code>r</code>を移動させるのに<a href="../base/parallel.html#Base.fetch-Tuple{Task}"><code>fetch</code></a>が 必要になる場合があるからです．この場合，<a href="../stdlib/Distributed.html#Distributed.@spawnat"><code>@spawnat</code></a>は<code>r</code>を所有しているプロセス上で計算を実行するのに 十分賢いので，<a href="../base/parallel.html#Base.fetch-Tuple{Task}"><code>fetch</code></a>はno-opです（処理は行われません）．</p><p>（<a href="../stdlib/Distributed.html#Distributed.@spawnat"><code>@spawnat</code></a>は組み込みではなく，Juliaで<a href="metaprogramming.html#man-macros">macro</a>として定義されているのは注記に値します． このような構造体を独自に定義することも可能です．）</p><p>覚えておくべき重要なことは，一度フェッチされると，<a href="../stdlib/Distributed.html#Distributed.Future"><code>Future</code></a>はその値をローカルにキャッシュする ということです．さらなる<a href="../base/parallel.html#Base.fetch-Tuple{Task}"><code>fetch</code></a>の呼び出しは，ネットワークホップを必要としません．すべての参照する <a href="../stdlib/Distributed.html#Distributed.Future"><code>Future</code></a>sをフェッチされると，リモートに格納されている値は削除される．</p><p><a href="../base/parallel.html#Base.@async"><code>@async</code></a>は<a href="../stdlib/Distributed.html#Distributed.@spawnat"><code>@spawnat</code></a>と似ていますが，ローカルプロセス上でしかタスクを動かしません． これを使って，各プロセスに「フィーダ」タスクを作成します．各タスクは計算が必要な次のインデックスを指定し， そのプロセスが終了するのを待ち，インデックスが無くなるまでこれを繰り返します．メインタスクが<a href="../base/parallel.html#Base.@sync"><code>@sync</code></a>の 最終ブロック，すなわち制御を放棄し関数から戻る前にすべてのローカルタスクが完了するのを末ポイントに到達するまで， フィーダタスクは実行を開始しないことに注意してください． v0.7以降では，フィーダタスクは，すべて同じプロセス上で実行されるため，<code>nextidx</code>を介して状態を共有することが できます．<code>Task</code>が協調的にスケジュールされていたとしても，<a href="faq.html#faq-async-io">asynchronous I/O</a>のように， コンテキストによってはロックが必要になる場合があります． これは，コンテキストスイッチは良く定義されたポイント，この場合は <a href="../stdlib/Distributed.html#Distributed.remotecall_fetch-Tuple{Any,Integer,Vararg{Any,N} where N}"><code>remotecall_fetch</code></a>が呼ばれた時のみ発生する ことを意味します．これは現在の実装の状態であり，将来のJuliaのバージョンでは，M個の<code>Process</code>上でN個まで<code>Tasks</code>を実行 する，<a href="https://en.wikipedia.org/wiki/Thread_(computing)#Models">M:N Threading</a>を可能にするために変更される 可能性があります．その場合，複数のプロセスに同時に単一のリソースへの読み書きを行わせるのはセーフでないため， <code>nextidx</code>用のロック獲得/再解放モデルが必要になります．</p><h2 id="code-availability"><a class="docs-heading-anchor" href="#code-availability">コードの利用可能性とパッケージの読み込み</a><a id="code-availability-1"></a><a class="docs-heading-anchor-permalink" href="#code-availability" title="Permalink"></a></h2><p>あなたのコードは，それを実行する全てのプロセスで利用可能でなければなりません．例えば， Juliaプロンプトに以下のように入力します:</p><pre><code class="language-julia-repl">julia&gt; function rand2(dims...)
           return 2*rand(dims...)
       end

julia&gt; rand2(2,2)
2×2 Array{Float64,2}:
 0.153756  0.368514
 1.15119   0.918912

julia&gt; fetch(@spawnat :any rand2(2,2))
ERROR: RemoteException(2, CapturedException(UndefVarError(Symbol(&quot;#rand2&quot;))
Stacktrace:
[...]</code></pre><p>プロセス1は関数<code>rand2</code>を知っていましたが，プロセス2は知りませんでした．</p><p>ほとんどの場合，あなたはファイルやパッケージからコードをロードすることになりますが，どのプロセスが コードをロードするのかはかなり柔軟に制御することができます．以下のようなコードを含む<code>DummyModule.jl</code> というファイルを考えてみましょう:</p><pre><code class="language-julia">module DummyModule

export MyType, f

mutable struct MyType
    a::Int
end

f(x) = x^2+1

println(&quot;loaded&quot;)

end</code></pre><p>全てのプロセスにわたって<code>MyType</code>を参照するためには，全てのプロセスで<code>DummyModule.jl</code>をロードする 必要があります．<code>include(&quot;DummyModule.jl&quot;)</code>を呼び出すと，単一のプロセス上でのみロードされます． 全てのプロセスでロードするには，<a href="../stdlib/Distributed.html#Distributed.@everywhere"><code>@everywhere</code></a>マクロを使用します．(<code>julia -p 2</code>でJuliaを開始します．):</p><pre><code class="language-julia-repl">julia&gt; @everywhere include(&quot;DummyModule.jl&quot;)
loaded
      From worker 3:    loaded
      From worker 2:    loaded</code></pre><p>いつものように，これは<code>DummyModule</code>をどのプロセスのスコープにも入れません，<code>using</code>または<code>import</code>を 必要とします．さらに，<code>DummyModule</code>を1つのプロセスのスコープに入れると，他のプロセスではスコープに入れません:</p><pre><code class="language-julia-repl">julia&gt; using .DummyModule

julia&gt; MyType(7)
MyType(7)

julia&gt; fetch(@spawnat 2 MyType(7))
ERROR: On worker 2:
UndefVarError: MyType not defined
⋮

julia&gt; fetch(@spawnat 2 DummyModule.MyType(7))
MyType(7)</code></pre><p>しかしながら，例えば，スコープに入っていないとしても，<code>DummyModule</code>をロードしたプロセスに <code>MyType</code>を送ることは可能です．</p><pre><code class="language-julia-repl">julia&gt; put!(RemoteChannel(2), MyType(7))
RemoteChannel{Channel{Any}}(2, 1, 13)</code></pre><p><code>-L</code>フラグを使って起動時に複数のプロセスにファイルをプリロードしたり，ドライバスクリプトを 使って計算を駆動したりすることもできます:</p><pre><code class="language-none">julia -p &lt;n&gt; -L file1.jl -L file2.jl driver.jl</code></pre><p>上の例のドライバスクリプトを実行しているJuliaプロセスは，対話型プロンプトを提供するプロセスと 同じように<code>id</code>として1を持ちます．</p><p>最後に，<code>DummyModule.jl</code>がスタンドアロンファイルではなくパッケージである場合，<code>using DummyModule</code> は全てのプロセスで<code>DummyModule.jl</code>を<em>ロード</em>しますが，<code>using</code>が呼ばれたプロセスでのみスコープに入ります．</p><h2 id="ワーカプロセスの開始と管理"><a class="docs-heading-anchor" href="#ワーカプロセスの開始と管理">ワーカプロセスの開始と管理</a><a id="ワーカプロセスの開始と管理-1"></a><a class="docs-heading-anchor-permalink" href="#ワーカプロセスの開始と管理" title="Permalink"></a></h2><p>基本となるJuliaのインストールでは，2種類のクラスタがサポートされています:</p><ul><li>上で示した通り，<code>-p</code>オプションで指定されたローカルクラスタ．</li><li><code>--machine-file</code>オプションを使ったマシンをまたいだクラスタ．これはパスワードなしの<code>ssh</code>ログインを</li></ul><pre><code class="language-none">使用して，指定されたマシン上で（現在のホストと同じパスから）Juliaワーカプロセスを起動します．</code></pre><p><a href="../stdlib/Distributed.html#Distributed.addprocs"><code>addprocs</code></a>, <a href="../stdlib/Distributed.html#Distributed.rmprocs"><code>rmprocs</code></a>, <a href="../stdlib/Distributed.html#Distributed.workers"><code>workers</code></a>などの関数が，クラスタ内のプロセスを追加， 削除，クエリするためのプログラム的な手段として利用できます．</p><pre><code class="language-julia-repl">julia&gt; using Distributed

julia&gt; addprocs(2)
2-element Array{Int64,1}:
 2
 3</code></pre><p>モジュール<code>Distributed</code>は<a href="../stdlib/Distributed.html#Distributed.addprocs"><code>addprocs</code></a>を呼び出す前に，マスタプロセス上で明示的にロードされなければなりません． ワーカプロセス上では自動的に利用可能になります．</p><p>ワーカは<code>~/.julia/config/startup.jl</code>スタートアップスクリプトを実行せず，またワーカはグローバル状態 （グローバル変数，新しいメソッド定義，ロードされたモジュール）を他の実行中のプロセスと同期させません． 特定の環境でワーカを初期化するために，<code>addprocs(exeflags=&quot;--project&quot;)</code>を使用し，その後<code>@everywhere using &lt;modulename&gt;</code> または<code>@everywhere include(&quot;file.jl&quot;)</code>を使用することができます．</p><p>他のタイプのクラスタは，以下の<a href="distributed-computing.html#ClusterManagers">ClusterManagers</a>で説明されているように，独自のカスタム<code>ClusterManager</code> を書くことでサポートすることができます．</p><h2 id="データ移動"><a class="docs-heading-anchor" href="#データ移動">データ移動</a><a id="データ移動-1"></a><a class="docs-heading-anchor-permalink" href="#データ移動" title="Permalink"></a></h2><p>メッセージの送信とデータの移動は，分散プログラムのオーバーヘッドの大部分を占めています． メッセージの数と送信されるデータの量を減らすことは，パフォーマンスとスケーラビリティを達成するために非常に重要です． この目的のために，Juliaの様々な分散プログラミング構造によって実行されるデータ移動を理解することが重要です．</p><p>考えることができます．<a href="../stdlib/Distributed.html#Distributed.@spawnat"><code>@spawnat</code></a>（といくつかの関連する構造）もデータを移動しますが，これは明らかではないので， 暗黙のデータ移動操作と呼ぶことができます．ランダム行列を構築して二乗するための2つのアプローチを考えてみましょう:</p><p>メソッド1:</p><pre><code class="language-julia-repl">julia&gt; A = rand(1000,1000);

julia&gt; Bref = @spawnat :any A^2;

[...]

julia&gt; fetch(Bref);</code></pre><p>メソッド2:</p><pre><code class="language-julia-repl">julia&gt; Bref = @spawnat :any rand(1000,1000)^2;

[...]

julia&gt; fetch(Bref);</code></pre><p>これらの違いは些細なように見えますが，実際には<a href="../stdlib/Distributed.html#Distributed.@spawnat"><code>@spawnat</code></a>の振る舞いによってかなり大きな違いがあります． 1つめのメソッドでは，ランダム行列が局所的に構築され，別のプロセスに送られて二乗されます．2つめのメソッドでは， ランダム行列は，別のプロセスで構築も二乗もされます．ゆえに，2つめのメソッドは1つめのメソッドよりもはるかに少ないデータを送信します．</p><p>このおもちゃの例では，この2つの方法は簡単に区別して選択することができます．しかし，実際のプログラムでは， データ移動の設計をするにはより多くの考えが必要であり，おそらく何らかの測定が必要になる場合があります． 例えば，1つめのプロセスが行列<code>A</code>を必要とする場合，1つめのメソッドが良いかもしれません．あるいは，<code>A</code>の 計算コストが高く現在のプロセスだけがそれを持っている場合は，他のプロセスへの移動は避けられないかもしれません． あるいは，現在のプロセスが<a href="../stdlib/Distributed.html#Distributed.@spawnat"><code>@spawnat</code></a>と<code>fetch(Bref)</code>の間にほとんど何もしない場合には，並列性を完全に 排除した方が良いかもしれません．あるいは，<code>rand(1000,1000)</code>がより計算コストのかかる処理に置き換えられることを 想像してみてください．その場合，このステップのためだけに，別の<a href="../stdlib/Distributed.html#Distributed.@spawnat"><code>@spawnat</code></a>文を追加するのが理にかなっている かもしれません．</p><h2 id="グローバル変数"><a class="docs-heading-anchor" href="#グローバル変数">グローバル変数</a><a id="グローバル変数-1"></a><a class="docs-heading-anchor-permalink" href="#グローバル変数" title="Permalink"></a></h2><p><code>@spawnat</code>経由でリモート実行される式や，<code>remotecall</code>を使ってリモートで実行するために指定されたクロージャは， グローバル変数を参照することがあります．<code>Main</code>モジュールの下のグローバルバインディングは， 他のモジュールのグローバルバインディングとは少し違った扱いになります．以下のコードスニペットを考えてみましょう:</p><pre><code class="language-julia-repl">A = rand(10,10)
remotecall_fetch(()-&gt;sum(A), 2)</code></pre><p>この場合，<a href="../base/collections.html#Base.sum"><code>sum</code></a>はリモートプロセスで定義されなければなりません．<code>A</code>はローカルのワークスペースで定義された グローバル変数であることに注意してください．ワーカ2は<code>Main</code>の下に<code>A</code>という変数を持っていません．クロージャ<code>()-&gt;sum(A)</code> をワーカ2に送る行為は<code>Main.A</code>がワーカ2に定義される結果となります．<code>remotecall_fetch</code>の呼び出しがリターンされた後も， ワーカ2の上に<code>Main.A</code>は存在し続けます．グローバル参照が埋め込まれたリモート呼び出し（<code>Main</code>モジュールの下でのみ）は， 以下のようにグローバルを管理します:</p><ul><li><p>リモートコールの一部といして参照されている場合，宛先ワーカに新しいグローバルバインディングが作成されます</p></li><li><p>グローバル定数はリモートノード上でも定数として宣言されます．</p></li><li><p>グローバル変数が宛先ワーカに再送信されるのは，リモート呼び出しのコンテキストのみで，その値が変更された 場合のみです．また，クラスタはノード間でグローバルバインディングを同期化しません．例えば以下のようになります:</p><pre><code class="language-julia">A = rand(10,10)
remotecall_fetch(()-&gt;sum(A), 2) # worker 2
A = rand(10,10)
remotecall_fetch(()-&gt;sum(A), 3) # worker 3
A = nothing</code></pre><p>上記のスニペットを実行すると，ワーカ2の<code>Main.A</code>はワーカ3の<code>Main.A</code>とは異なる値を持ち， ノード1の<code>Main.A</code>の値は何も設定されません．</p></li></ul><p>お気付きかもしれませんが，マスタ上で再割り当てられたされたときにグローバルに関連付けられたメモリが収集される 場合がありますが，バインディングが有効であり続けるため，ワーカにはそのようなアクションは実行されません． <a href="../stdlib/Distributed.html#Distributed.clear!-Tuple{CachingPool}"><code>clear!</code></a>を使用すると，リモートのノード上の特定のグローバルが不要になったら，手動でそれらを<code>nothing</code>へ 再割り当てすることができます．これにより，通常のガベージコレクションサイクルの一部として，それらに関連付けられた メモリが解放されます．</p><p>したがって，プログラムはリモート呼び出しの際のグローバルの参照に注意する必要があります．実際には，可能であれば 完全に避けることが望ましいです．グローバルを参照する必要がある場合は，グローバル変数をローカライズするために， <code>let</code>ブロックを使用することを検討してください．</p><p>以下は例です:</p><pre><code class="language-julia-repl">julia&gt; A = rand(10,10);

julia&gt; remotecall_fetch(()-&gt;A, 2);

julia&gt; B = rand(10,10);

julia&gt; let B = B
           remotecall_fetch(()-&gt;B, 2)
       end;

julia&gt; @fetchfrom 2 InteractiveUtils.varinfo()
name           size summary
––––––––– ––––––––– ––––––––––––––––––––––
A         800 bytes 10×10 Array{Float64,2}
Base                Module
Core                Module
Main                Module</code></pre><p>このように，グローバル変数<code>A</code>はワーカ2上で定義されていますが，<code>B</code>はローカル変数として捉えられているため， ワーカ2上には<code>B</code>のバインディングが存在しません．</p><h2 id="並列マップとループ"><a class="docs-heading-anchor" href="#並列マップとループ">並列マップとループ</a><a id="並列マップとループ-1"></a><a class="docs-heading-anchor-permalink" href="#並列マップとループ" title="Permalink"></a></h2><p>幸いなことに多くの有用な並列計算はデータ移動を必要としません．一般的な例としては， 複数のプロセスが独立したシミュレーション試行を同時に処理することができるモンテカルロシミュレーションがあります． ここでは，<a href="../stdlib/Distributed.html#Distributed.@spawnat"><code>@spawnat</code></a>を使って，2つのプロセスでコインを反転させることができます．まず，<code>count_heads.jl</code>に 以下のような関数を書きます:</p><pre><code class="language-julia">function count_heads(n)
    c::Int = 0
    for i = 1:n
        c += rand(Bool)
    end
    c
end</code></pre><p>関数<code>count_heads</code>は，単純に<code>n</code>個のランダムビットを加算します．ここでは，2つのマシンでいくつかの 試行を行い，その結果を足し合わせる方法を示します．</p><pre><code class="language-julia-repl">julia&gt; @everywhere include_string(Main, $(read(&quot;count_heads.jl&quot;, String)), &quot;count_heads.jl&quot;)

julia&gt; a = @spawnat :any count_heads(100000000)
Future(2, 1, 6, nothing)

julia&gt; b = @spawnat :any count_heads(100000000)
Future(3, 1, 7, nothing)

julia&gt; fetch(a)+fetch(b)
100001564</code></pre><p>この例は，今日六でよく使われる並列プログラミングパターンを示しています．多くの反復処理はいくつかの プロセスで独立して実行され，その結果が何らかの関数を使って結合されます． この組み合わせのプロセスは<em>reduction</em>と呼ばれます，なぜならそれは一般的にtensor-rank-reducingだからです:  あるベクトルが1つの数に削減されたり，行列が1つの行や列に削減されたりすることから，こう呼びます． コードでは，これは通常，<code>x = f(x,v[i])</code>というパターンのように見えます．ここで<code>x</code>はアキュムレータ， <code>f</code>はリダクション関数，<code>v[i]</code>はリデュースされる要素です．演算がどのような順序で実行されても問題ないように， <code>f</code>は結合律を満たしていることが望ましいです．</p><p><code>count_heads</code>でのこのパターンの使用は一般化できることに注意してください．2つの明示的な<a href="../stdlib/Distributed.html#Distributed.@spawnat"><code>@spawnat</code></a>文を 使用しているので，並列処理は2つのプロセスに制限されています．任意の数のプロセスで実行するためには， 分散メモリで実行する<em>parallel for loop</em>を使うことができ，これはJuliaでは<a href="../stdlib/Distributed.html#Distributed.@distributed"><code>@distributed</code></a>を 使って以下のように書くことができます:</p><pre><code class="language-julia">nheads = @distributed (+) for i = 1:200000000
    Int(rand(Bool))
end</code></pre><p>この構文は複数のプロセスに反復処理を割り当て，指定されたリダクション（ここでは<code>(+)</code>）と組み合わせるパターンを 実装しています．各反復の結果は，ループ内の最後の式の値として取られます．並列ループ全体の式自体は， 最終的な答えとして評価されます．</p><p>並列ループはシリアルループのように見えますが，動作は劇的に異なることに注意してください．特に， 反復は指定された順序では行われず，変数や配列への書き込みは，反復が異なるプロセスで実行されるため， グローバルには表示されません．並列ループ内で使用される変数は全てコピーされ，各プロセスにブロードキャストされます．</p><p>例えば，以下のようなコードは意図通りには動きません:</p><pre><code class="language-julia">a = zeros(100000)
@distributed for i = 1:100000
    a[i] = i
end</code></pre><p>このコードでは，各プロセスが個別のコピーを持つことになるので，全ての<code>a</code>を初期化することはできません． このようなループのための並列化は避けなければなりません．幸いなことに，<a href="distributed-computing.html#man-shared-arrays">Shared Arrays</a> を使うことで，この制限を回避することができます:</p><pre><code class="language-julia">using SharedArrays

a = SharedArray{Float64}(10)
@distributed for i = 1:10
    a[i] = i
end</code></pre><p>変数が読み取り専用であれば，並列ループで「外部」変数を使用するのは完全に合理的です:</p><pre><code class="language-julia">a = randn(1000)
@distributed (+) for i = 1:100000
    f(a[rand(1:end)])
end</code></pre><p>ここでは，各反復処理は，全ての処理で共有されるベクトル<code>a</code>からランダムに選択されたサンプルに対して<code>f</code>を適用します．</p><p>ここで見た通り，リダクション演算子は必要なければ省略することができます．その場合，ループは非同期に実行される． つまり，利用可能な全てのワーカ上で独立したタスクを生成し，完了を待たずに直ちに<a href="../stdlib/Distributed.html#Distributed.Future"><code>Future</code></a>の 配列を返します．呼び出し元は，<a href="../stdlib/Distributed.html#Distributed.Future"><code>Future</code></a>の完了を後のポイントで<a href="../base/parallel.html#Base.fetch-Tuple{Task}"><code>fetch</code></a>を呼び出すことで 待つか，ループの最後に<code>@sync @distributed for</code>のように<a href="../base/parallel.html#Base.@sync"><code>@sync</code></a>を接頭辞としてつけることにより完了を待つことができる．</p><p>場合によってはリダクション演算子は必要とされず，ある範囲の全ての整数（またはより一般的には，あるコレクションの全ての要素） に関数を適用したいだけの場合もあります．これは<em>parallel map</em>と呼ばれるもう一つの便利な操作で，Juliaでは <a href="../stdlib/Distributed.html#Distributed.pmap"><code>pmap</code></a>関数として実装されています．例えば，以下のようにいくつかの大きな乱数行列の特異値を並列に計算することができます:</p><pre><code class="language-julia-repl">julia&gt; M = Matrix{Float64}[rand(1000,1000) for i = 1:10];

julia&gt; pmap(svdvals, M);</code></pre><p>Juliaの<a href="../stdlib/Distributed.html#Distributed.pmap"><code>pmap</code></a>は各関数呼び出しが大量の作業を行う場合のために設計されています． 対照的に<code>@distributed for</code>は，それぞれの反復が小さなもので，おそらく2つの数値を合計するだけのような状況を 扱うことができます．<a href="../stdlib/Distributed.html#Distributed.pmap"><code>pmap</code></a>と<code>@distributed for</code>は並列計算のためにワーカプロセスのみを使用します． <code>@distributed for</code>を使う場合には，最終的なリダクションは呼び出したプロセスで行われます．</p><h2 id="リモートリファレンスとアブストラクトチャネル"><a class="docs-heading-anchor" href="#リモートリファレンスとアブストラクトチャネル">リモートリファレンスとアブストラクトチャネル</a><a id="リモートリファレンスとアブストラクトチャネル-1"></a><a class="docs-heading-anchor-permalink" href="#リモートリファレンスとアブストラクトチャネル" title="Permalink"></a></h2><p>リモートリファレンスは常に<code>AbstractChannel</code>の実装を参照します．</p><p>（<code>Channel</code>のような）<code>AbstractChannel</code>の具体的な実装は<a href="../base/parallel.html#Base.put!-Tuple{Channel,Any}"><code>put!</code></a>，<a href="../base/io-network.html#Base.take!-Tuple{Base.GenericIOBuffer}"><code>take!</code></a>， <a href="../base/parallel.html#Base.fetch-Tuple{Task}"><code>fetch</code></a>， <a href="../base/parallel.html#Base.isready-Tuple{Channel}"><code>isready</code></a>および<a href="../base/parallel.html#Base.wait"><code>wait</code></a>を実装するのに必要とされます． <a href="../stdlib/Distributed.html#Distributed.Future"><code>Future</code></a>によって参照されるリモートオブジェクトは，<code>Channel{Any}(1)</code>，すなわち <code>Any</code>タイプのオブジェクトを保持することのできるサイズ1の<code>Channel</code>に格納されます．</p><p><a href="../stdlib/Distributed.html#Distributed.RemoteChannel"><code>RemoteChannel</code></a>は上書き可能ですが，任意の型やサイズのチャネル，あるいは<code>AbstractChannel</code>の 他の実装を指定することができます．</p><p>コンストラクタ<code>RemoteChannel(f::Function, pid)()</code>を使用すると，特定の型の複数の値を保持するチャネルへの 参照を作成することができます．<code>f</code>は<code>pid</code>上で実行される関数であり，<code>AbstractChannel</code>を返さなければなりません．</p><p>例えば，<code>RemoteChannel(()-&gt;Channel{Int}(10), pid)</code>はInt型でサイズ10のチャネルへの参照を返します． このチャネルはワーカ<code>pid</code>上に存在します．</p><p><a href="../stdlib/Distributed.html#Distributed.RemoteChannel"><code>RemoteChannel</code></a>上のメソッド<a href="../base/parallel.html#Base.put!-Tuple{Channel,Any}"><code>put!</code></a>，<a href="../base/io-network.html#Base.take!-Tuple{Base.GenericIOBuffer}"><code>take!</code></a>，<a href="../base/parallel.html#Base.fetch-Tuple{Task}"><code>fetch</code></a>，<a href="../base/parallel.html#Base.isready-Tuple{Channel}"><code>isready</code></a>および<a href="../base/parallel.html#Base.wait"><code>wait</code></a> は，リモートプロセス上のバッキングストアにプロキシされます．</p><p>このように，<a href="../stdlib/Distributed.html#Distributed.RemoteChannel"><code>RemoteChannel</code></a>はユーザが実装した<code>AbstractChannel</code>オブジェクトを参照するために 使用することができます．この単純な例は，<a href="https://github.com/JuliaAttic/Examples">Examples repository</a> の<code>dictchannel.jl</code>で提供されており，リモートストアとして辞書を使用しています．</p><h2 id="チャネルとリモートチャネル"><a class="docs-heading-anchor" href="#チャネルとリモートチャネル">チャネルとリモートチャネル</a><a id="チャネルとリモートチャネル-1"></a><a class="docs-heading-anchor-permalink" href="#チャネルとリモートチャネル" title="Permalink"></a></h2><ul><li><a href="../base/parallel.html#Base.Channel"><code>Channel</code></a>はプロセスに対してローカルなものです．ワーカ2がワーカ3の<a href="../base/parallel.html#Base.Channel"><code>Channel</code></a>を直接参照することはできませんが，<a href="../stdlib/Distributed.html#Distributed.RemoteChannel"><code>RemoteChannel</code></a>はワーカ間で値を入れたり出したりすることができます．</li><li><a href="../stdlib/Distributed.html#Distributed.RemoteChannel"><code>RemoteChannel</code></a>は<a href="../base/parallel.html#Base.Channel"><code>Channel</code></a>の<em>handle</em>と考えることができます．</li><li><a href="../stdlib/Distributed.html#Distributed.RemoteChannel"><code>RemoteChannel</code></a>に関連付けられたプロセスid<code>pid</code>は，バッキングストアが存在するプロセス言い換えるとバッキング<a href="../base/parallel.html#Base.Channel"><code>Channel</code></a>が存在するプロセスを識別します．</li><li><a href="../stdlib/Distributed.html#Distributed.RemoteChannel"><code>RemoteChannel</code></a>への参照を持つ全てのプロセスは，チャネルからアイテムを入れたり出したりできます．データは<a href="../stdlib/Distributed.html#Distributed.RemoteChannel"><code>RemoteChannel</code></a>が関連付けられているプロセスに自動的に送信されます（またはそこから取得されます）．</li><li><a href="../base/parallel.html#Base.Channel"><code>Channel</code></a>をシリアライズすると，チャネル内に存在する全てのデータもシリアライズされます．そのため，チャネルをデシリアライズすると，元のオブジェクトのコピーが効果的に作成されます．</li><li>一方，<a href="../stdlib/Distributed.html#Distributed.RemoteChannel"><code>RemoteChannel</code></a>をシリアライズすると，ハンドルが参照している<a href="../base/parallel.html#Base.Channel"><code>Channel</code></a>の場所とインスタンスを識別する識別子のシリアライズのみが行われます．したがって，（任意のワーカ上の）デシリアライズされた<a href="../stdlib/Distributed.html#Distributed.RemoteChannel"><code>RemoteChannel</code></a>オブジェクトはオリジナルと同じバッキングストアを指すことになります</li></ul><p>上記のチャネルの例は，以下のようにプロセス間通信のために変更することができます．</p><p>単一の<code>jobs</code>リモートチャネルを処理するために4つのワーカを起動します．Jobsは<code>job_id</code>によって識別され， そのチャネルに書き込まれます．このシミュレーションでは各リモート実行タスクは<code>job_id</code>を読み込み， ランダムな時間だけ待機し，<code>job_id</code>，かかった時間，自身の<code>pid</code>のタプルを結果チャネルに書き戻します． 最後に，全ての結果がマスタプロセスに出力されます．</p><pre><code class="language-julia-repl">julia&gt; addprocs(4); # add worker processes

julia&gt; const jobs = RemoteChannel(()-&gt;Channel{Int}(32));

julia&gt; const results = RemoteChannel(()-&gt;Channel{Tuple}(32));

julia&gt; @everywhere function do_work(jobs, results) # define work function everywhere
           while true
               job_id = take!(jobs)
               exec_time = rand()
               sleep(exec_time) # simulates elapsed time doing actual work
               put!(results, (job_id, exec_time, myid()))
           end
       end

julia&gt; function make_jobs(n)
           for i in 1:n
               put!(jobs, i)
           end
       end;

julia&gt; n = 12;

julia&gt; @async make_jobs(n); # feed the jobs channel with &quot;n&quot; jobs

julia&gt; for p in workers() # start tasks on the workers to process requests in parallel
           remote_do(do_work, p, jobs, results)
       end

julia&gt; @elapsed while n &gt; 0 # print out results
           job_id, exec_time, where = take!(results)
           println(&quot;$job_id finished in $(round(exec_time; digits=2)) seconds on worker $where&quot;)
           global n = n - 1
       end
1 finished in 0.18 seconds on worker 4
2 finished in 0.26 seconds on worker 5
6 finished in 0.12 seconds on worker 4
7 finished in 0.18 seconds on worker 4
5 finished in 0.35 seconds on worker 5
4 finished in 0.68 seconds on worker 2
3 finished in 0.73 seconds on worker 3
11 finished in 0.01 seconds on worker 3
12 finished in 0.02 seconds on worker 3
9 finished in 0.26 seconds on worker 5
8 finished in 0.57 seconds on worker 4
10 finished in 0.58 seconds on worker 2
0.055971741</code></pre><h3 id="リモートリファレンスと分散ガベージコレクション"><a class="docs-heading-anchor" href="#リモートリファレンスと分散ガベージコレクション">リモートリファレンスと分散ガベージコレクション</a><a id="リモートリファレンスと分散ガベージコレクション-1"></a><a class="docs-heading-anchor-permalink" href="#リモートリファレンスと分散ガベージコレクション" title="Permalink"></a></h3><p>リモートリファレンスによって参照されるオブジェクトはクラスタ内で保持されている<em>全ての</em>参照が 削除されたときにのみ解放されることができます．</p><p>値が格納されているノードは，どのワーカがその値への参照を持っているかを追跡します． <a href="../stdlib/Distributed.html#Distributed.RemoteChannel"><code>RemoteChannel</code></a>や（フェッチされていない）<a href="../stdlib/Distributed.html#Distributed.Future"><code>Future</code></a>がワーカにシリアライズされるたびに， 参照先のノードが通知されます．また，<a href="../stdlib/Distributed.html#Distributed.RemoteChannel"><code>RemoteChannel</code></a>や（フェッチされていない）<a href="../stdlib/Distributed.html#Distributed.Future"><code>Future</code></a>が ローカルでガベージコレクションされるたびに，値を所有するノードは再度通知される．これは内部クラスタを意識した シリアライザで実装されています．リモート参照は実行中のクラスタのコンテキストでのみ有効です．通常の<code>IO</code>オブジェクトへの， または通常の<code>IO</code>オブジェクトからの参照のシリアライズとデシリアライズはサポートされていません．</p><p>この通知は参照が別のプロセスにシリアライズされた場合は，「参照を追加」メッセージ，参照がローカルで ガベージコレクションされた場合には「参照を削除」メッセージという「トラッキングメッセージ」の送信によって 行われます．</p><p><a href="../stdlib/Distributed.html#Distributed.Future"><code>Future</code></a>は一度限りの書き込みでローカルにキャッシュされるので， <a href="../stdlib/Distributed.html#Distributed.Future"><code>Future</code></a>を<a href="../base/parallel.html#Base.fetch-Tuple{Task}"><code>fetch</code></a>する行為は，値を所有しているノードの参照トラッキング情報も更新する．</p><p>値を所有しているノードは，値への全ての参照がクリアされると，値を解放します．</p><p><a href="../stdlib/Distributed.html#Distributed.Future"><code>Future</code></a>では，オリジナルのリモートストアがこの時点までに値を収集している場合があるので， すでに別のノードへフェッチされた<a href="../stdlib/Distributed.html#Distributed.Future"><code>Future</code></a>をシリアライズした時も値を送信します．</p><p>オブジェクトが<em>いつ</em>ローカルでガベージコレクションされるのかが，オブジェクトのサイズとシステム内の 現在のメモリプレッシャに依存することに注意することは重要です．</p><p>リモートリファレンスの場合，ローカルリファレンスオブジェクトのサイズはかなり小さいですが，リモートノードに 格納されている値はかなり大きいかもしれません．ローカルオブジェクトはすぐに収集されない可能性があるので， <a href="../stdlib/Distributed.html#Distributed.RemoteChannel"><code>RemoteChannel</code></a>のローカルインスタンスや，フェッチされていない<a href="../stdlib/Distributed.html#Distributed.Future"><code>Future</code></a>に 対して明示的に<a href="../base/base.html#Base.finalize"><code>finalize</code></a>を呼び出すのが良い方法です．<a href="../stdlib/Distributed.html#Distributed.Future"><code>Future</code></a>に対して， <a href="../base/parallel.html#Base.fetch-Tuple{Task}"><code>fetch</code></a>を呼び出すと，リモートストアからの参照も削除されるので，フェッチされた<a href="../stdlib/Distributed.html#Distributed.Future"><code>Future</code></a>sに 対してはこれは必要ありません．明示的に<a href="../base/base.html#Base.finalize"><code>finalize</code></a>を呼び出すと，リモートノードに値への参照を削除するための 即時メッセージが送信されます．</p><p>一度ファイナライズされると，参照は無効になり，それ以降の呼び出しでは使用できなくなります．</p><h2 id="ローカルな呼び出し"><a class="docs-heading-anchor" href="#ローカルな呼び出し">ローカルな呼び出し</a><a id="ローカルな呼び出し-1"></a><a class="docs-heading-anchor-permalink" href="#ローカルな呼び出し" title="Permalink"></a></h2><p>実行のためにデータは必然敵にリモートノードにコピーされる．これはリモートコールの場合と， データが別のノードの<a href="../stdlib/Distributed.html#Distributed.RemoteChannel"><code>RemoteChannel</code></a> / <a href="../stdlib/Distributed.html#Distributed.Future"><code>Future</code></a>に格納されている場合の両方に当てはまる． 予想通り，これはリモートノード上のシリアライズされたオブジェクトのコピーになります．しかし，宛先ノードが ローカルノードである場合，つまり呼び出し元のプロセスIDがリモートノードIDと同じである場合は，ローカルコールとして 実行されます．通常は（常にではありませんが）別のタスクで実行されますが，データのシリアライズ/デシリアライズは 行われません．その結果，コールは渡されたものと同じオブジェクトインスタンスを参照します，この時コピーは作成されません． この動作を以下に示します．</p><pre><code class="language-julia-repl">julia&gt; using Distributed;

julia&gt; rc = RemoteChannel(()-&gt;Channel(3));   # RemoteChannel created on local node

julia&gt; v = [0];

julia&gt; for i in 1:3
           v[1] = i                          # Reusing `v`
           put!(rc, v)
       end;

julia&gt; result = [take!(rc) for _ in 1:3];

julia&gt; println(result);
Array{Int64,1}[[3], [3], [3]]

julia&gt; println(&quot;Num Unique objects : &quot;, length(unique(map(objectid, result))));
Num Unique objects : 1

julia&gt; addprocs(1);

julia&gt; rc = RemoteChannel(()-&gt;Channel(3), workers()[1]);   # RemoteChannel created on remote node

julia&gt; v = [0];

julia&gt; for i in 1:3
           v[1] = i
           put!(rc, v)
       end;

julia&gt; result = [take!(rc) for _ in 1:3];

julia&gt; println(result);
Array{Int64,1}[[1], [2], [3]]

julia&gt; println(&quot;Num Unique objects : &quot;, length(unique(map(objectid, result))));
Num Unique objects : 3</code></pre><p>見て取られるように，ローカルに所有されている<a href="../stdlib/Distributed.html#Distributed.RemoteChannel"><code>RemoteChannel</code></a>に呼び出しの間に修正された 同一のオブジェクト<code>v</code>を<a href="../base/parallel.html#Base.put!-Tuple{Channel,Any}"><code>put!</code></a>すると，同じ単一のオブジェクトインスタンスが格納されます． これは，<code>rc</code>を所有しているノードが別のノードである場合に<code>v</code>のコピーが作成されるのとは対照的です．</p><p>これは一般的には問題ではないことに注意してください．これは，オブジェクトがローカルに保存されている場合と， 呼び出し後に変更されている場合にのみ考慮すべきことです．そのような場合は，オブジェクトの<code>deepcopy</code>を 保存するのが適切かもしれません．</p><p>これは，次の例のようにローカルノード上のリモートコールにも当てはまります:</p><pre><code class="language-julia-repl">julia&gt; using Distributed; addprocs(1);

julia&gt; v = [0];

julia&gt; v2 = remotecall_fetch(x-&gt;(x[1] = 1; x), myid(), v);     # Executed on local node

julia&gt; println(&quot;v=$v, v2=$v2, &quot;, v === v2);
v=[1], v2=[1], true

julia&gt; v = [0];

julia&gt; v2 = remotecall_fetch(x-&gt;(x[1] = 1; x), workers()[1], v); # Executed on remote node

julia&gt; println(&quot;v=$v, v2=$v2, &quot;, v === v2);
v=[0], v2=[1], false</code></pre><p>再度見て取れるように，ローカルノードへのリモート呼び出しは，直接呼び出しと同じように動作します． 呼び出しは引数として渡されたローカルオブジェクトを変更します．リモート呼び出しでは，引数のコピーを操作します．</p><p>繰り返しになりますが，これは一般的には問題になりません．ローカルノードが計算ノードとしても使用されており， 呼び出し後に引数が使用されている場合，要求された引数のディープコピーをローカルノードで実行するコールへ渡さねば ならないときには，このディープコピーの中で，この動作を考慮する必要があります．</p><h2 id="man-shared-arrays"><a class="docs-heading-anchor" href="#man-shared-arrays">Shared Arrays</a><a id="man-shared-arrays-1"></a><a class="docs-heading-anchor-permalink" href="#man-shared-arrays" title="Permalink"></a></h2><p>Shared Arraysはシステムの共有メモリを使用して，多くのプロセスにわたって同じ配列をマッピングします． <a href="https://github.com/JuliaParallel/DistributedArrays.jl"><code>DArray</code></a>といくつかの類似点がありますが， <a href="../stdlib/SharedArrays.html#SharedArrays.SharedArray"><code>SharedArray</code></a>の動作はかなり異なります．<a href="https://github.com/JuliaParallel/DistributedArrays.jl"><code>DArray</code></a>では， 各プロセスはデータのチャンクへのローカルアクセス権を持ち，2つのプロセスが同じチャンクを共有することはありません: 対照的に，<a href="../stdlib/SharedArrays.html#SharedArrays.SharedArray"><code>SharedArray</code></a>では各「参加」プロセスは，配列全体にアクセスすることができます． <a href="../stdlib/SharedArrays.html#SharedArrays.SharedArray"><code>SharedArray</code></a>は，同じマシン上の2つ以上のプロセスが共同でアクセスできる大量のデータを持ちたい場合に良い選択です．</p><p>Shared Arrayのサポートは，参加している全てのワーカ上で明示的にロードされなければならない<code>SharedArrays</code> モジュールを介して利用可能です．</p><p><a href="../stdlib/SharedArrays.html#SharedArrays.SharedArray"><code>SharedArray</code></a>のインデクシング（値の代入とアクセス）は通常の配列と同じように動作し， ローカルプロセスで利用可能なメモリ上で動作しているので効率的です．したがって，シングルプロセスモードとはいえ， ほとんどのアルゴリズムは自然に<a href="../stdlib/SharedArrays.html#SharedArrays.SharedArray"><code>SharedArray</code></a>s上で動作します．アルゴリズムが<a href="../base/arrays.html#Core.Array"><code>Array</code></a>入力を要求 する場合，<a href="../stdlib/SharedArrays.html#SharedArrays.sdata"><code>sdata</code></a>を呼ぶことによって，<a href="../stdlib/SharedArrays.html#SharedArrays.SharedArray"><code>SharedArray</code></a>からその下にある配列を取得することができます． 他の<code>AbstractArray</code>型の場合，<a href="../stdlib/SharedArrays.html#SharedArrays.sdata"><code>sdata</code></a>はオブジェクト自体を返すだけなので，どんな<code>Array</code>型のオブジェクト上で <a href="../stdlib/SharedArrays.html#SharedArrays.sdata"><code>sdata</code></a>を使ってもセーフです．</p><p>Shared Arrayのコンストラクタは以下の形式です:</p><pre><code class="language-julia">SharedArray{T,N}(dims::NTuple; init=false, pids=Int[])</code></pre><p>これは<code>pids</code>で指定されたプロセス間でビット型<code>T</code>とサイズ<code>dims</code>の<code>N</code>次元のshared arrayを作成します． 分散配列とは異なり，shared arrayは引数に指定された<code>pids</code>で指定された参加ワーカからのみアクセス可能です（ 同じホスト上にある場合は作成プロセスからもアクセス可能です．）SharedArrayでは，<a href="../base/base.html#Base.isbits"><code>isbits</code></a>である 要素のみがサポートされていることに注意してください．</p><p>シグネチャ<code>initfn(S::SharedArray)</code>の<code>init</code>関数が指定された場合，参加している全てのワーカ上で呼び出されます． 各ワーカが配列の異なる部分で<code>init</code>関数を実行できるように指定することで，初期化を並列化することができます．</p><p>以下に簡単な例を示します:</p><pre><code class="language-julia-repl">julia&gt; using Distributed

julia&gt; addprocs(3)
3-element Array{Int64,1}:
 2
 3
 4

julia&gt; @everywhere using SharedArrays

julia&gt; S = SharedArray{Int,2}((3,4), init = S -&gt; S[localindices(S)] = repeat([myid()], length(localindices(S))))
3×4 SharedArray{Int64,2}:
 2  2  3  4
 2  3  3  4
 2  3  4  4

julia&gt; S[3,2] = 7
7

julia&gt; S
3×4 SharedArray{Int64,2}:
 2  2  3  4
 2  3  3  4
 2  7  4  4</code></pre><p><a href="../stdlib/SharedArrays.html#SharedArrays.localindices"><code>SharedArrays.localindices</code></a>はインデックスの不連続な一次元の範囲を提供し，プロセス間でタスクを分割するのに 便利なことがあります．もちろん好きなように作業を分割することができます:</p><pre><code class="language-julia-repl">julia&gt; S = SharedArray{Int,2}((3,4), init = S -&gt; S[indexpids(S):length(procs(S)):length(S)] = repeat([myid()], length( indexpids(S):length(procs(S)):length(S))))
3×4 SharedArray{Int64,2}:
 2  2  2  2
 3  3  3  3
 4  4  4  4</code></pre><p>全てのプロセスが下にあるデータにアクセスできるので，コンフリクトを起こさないように気を付けなければなりません． 例えば:</p><pre><code class="language-julia">@sync begin
    for p in procs(S)
        @async begin
            remotecall_wait(fill!, p, S, p)
        end
    end
end</code></pre><p>これは定義されていない挙動を生む結果となります．各々のプロセスは自身の<code>pid</code>で配列<em>全体</em>を埋めるので， 最後に（Sの任意の特定の要素に対して）実行したプロセスがいずれであっても，その<code>pid</code>を保持することになります．</p><p>より拡張された複雑な例として，以下の「カーネル」を並列に実行することを考えてみましょう:</p><pre><code class="language-julia">q[i,j,t+1] = q[i,j,t] + u[i,j,t]</code></pre><p>この場合，1次元のインデックスを使って作業を分割しようとすると，問題が発生する可能性があります: <code>q[i,j,t]</code>があるワーカに割り当てられたブロックの終わり近くにあり，<code>q[i,j,t+1]</code>が別のワーカに割り当て られたブロックの始まり近くにある場合，<code>q[i,j,t]</code>が<code>q[i,j,t+1]</code>を計算するのに必要な時間に準備できていない 可能性が高いです．このような場合には，手動で配列をチャンクした方が良いでしょう．2つ目の次元に沿って 分割してみましょう．このワーカに割り当てられた<code>(irange, jrange)</code>インデックスを返す関数を定義します:</p><pre><code class="language-julia-repl">julia&gt; @everywhere function myrange(q::SharedArray)
           idx = indexpids(q)
           if idx == 0 # This worker is not assigned a piece
               return 1:0, 1:0
           end
           nchunks = length(procs(q))
           splits = [round(Int, s) for s in range(0, stop=size(q,2), length=nchunks+1)]
           1:size(q,1), splits[idx]+1:splits[idx+1]
       end</code></pre><p>次に，カーネルを定義します:</p><pre><code class="language-julia-repl">julia&gt; @everywhere function advection_chunk!(q, u, irange, jrange, trange)
           @show (irange, jrange, trange)  # display so we can see what&#39;s happening
           for t in trange, j in jrange, i in irange
               q[i,j,t+1] = q[i,j,t] + u[i,j,t]
           end
           q
       end</code></pre><p><code>SharedArray</code>実装のために便利なラッパも定義します:</p><pre><code class="language-julia-repl">julia&gt; @everywhere advection_shared_chunk!(q, u) =
           advection_chunk!(q, u, myrange(q)..., 1:size(q,3)-1)</code></pre><p>では3つの異なるバージョンを比べてみましょう．シングルプロセスで動作させた場合:</p><pre><code class="language-julia-repl">julia&gt; advection_serial!(q, u) = advection_chunk!(q, u, 1:size(q,1), 1:size(q,2), 1:size(q,3)-1);</code></pre><p><a href="../stdlib/Distributed.html#Distributed.@distributed"><code>@distributed</code></a>を使った場合:</p><pre><code class="language-julia-repl">julia&gt; function advection_parallel!(q, u)
           for t = 1:size(q,3)-1
               @sync @distributed for j = 1:size(q,2)
                   for i = 1:size(q,1)
                       q[i,j,t+1]= q[i,j,t] + u[i,j,t]
                   end
               end
           end
           q
       end;</code></pre><p>そしてチャンクに委譲した場合:</p><pre><code class="language-julia-repl">julia&gt; function advection_shared!(q, u)
           @sync begin
               for p in procs(q)
                   @async remotecall_wait(advection_shared_chunk!, p, q, u)
               end
           end
           q
       end;</code></pre><p><code>SharedArray</code>sを作成してこれらの関数を実行すると，以下のような結果が得られます（<code>julia -p 4</code>を用いた場合）:</p><pre><code class="language-julia-repl">julia&gt; q = SharedArray{Float64,3}((500,500,500));

julia&gt; u = SharedArray{Float64,3}((500,500,500));</code></pre><p>関数を一度実行してJITコンパイルし，2回目の実行時に <a href="../base/base.html#Base.@time"><code>@time</code></a>で計測します:</p><pre><code class="language-julia-repl">julia&gt; @time advection_serial!(q, u);
(irange,jrange,trange) = (1:500,1:500,1:499)
 830.220 milliseconds (216 allocations: 13820 bytes)

julia&gt; @time advection_parallel!(q, u);
   2.495 seconds      (3999 k allocations: 289 MB, 2.09% gc time)

julia&gt; @time advection_shared!(q,u);
        From worker 2:       (irange,jrange,trange) = (1:500,1:125,1:499)
        From worker 4:       (irange,jrange,trange) = (1:500,251:375,1:499)
        From worker 3:       (irange,jrange,trange) = (1:500,126:250,1:499)
        From worker 5:       (irange,jrange,trange) = (1:500,376:500,1:499)
 238.119 milliseconds (2264 allocations: 169 KB)</code></pre><p><code>advection_shared!</code>の最大の利点は，ワーカ間のトラフィックを最小限に抑え，各ワーカが割り当てられたピースで 長時間計算することを可能にすることです．</p><h3 id="Shared-Arraysと分散ガベージコレクション"><a class="docs-heading-anchor" href="#Shared-Arraysと分散ガベージコレクション">Shared Arraysと分散ガベージコレクション</a><a id="Shared-Arraysと分散ガベージコレクション-1"></a><a class="docs-heading-anchor-permalink" href="#Shared-Arraysと分散ガベージコレクション" title="Permalink"></a></h3><p>リモートリファレンスと同様に，shared arraysもまた，参加している全てのワーカから参照を解放をするのに， 作成ノードのガベージコレクションに依存しています．短期間で多くのshared arrayオブジェクトを作成するコードでは， これらのオブジェクトをできるだけ早く明示的にファイナライズすることが有益です．これにより，共有セグメントを マッピングするメモリとファイルハンドルの両方がより早く解放されるようになります．</p><h2 id="ClusterManagers"><a class="docs-heading-anchor" href="#ClusterManagers">ClusterManagers</a><a id="ClusterManagers-1"></a><a class="docs-heading-anchor-permalink" href="#ClusterManagers" title="Permalink"></a></h2><p>論理クラスタへのJuliaプロセスの起動，管理，ネットワーキングは，クラスタマネージャを介して行われます． <code>ClusterManager</code>は以下を担当します:</p><ul><li>クラスタ環境下におけるワーカプロセスの起動</li><li>各ワーカのライフタイムの間のイベント管理</li><li>オプションで，データ転送を提供</li></ul><p>Juliaクラスタは以下のような特徴を持ちます:</p><ul><li>最初のJuliaプロセスは<code>master</code>とも呼ばれますが，これは特別なもので，<code>id</code>として1を持ちます．</li><li><code>master</code>プロセスだけが，ワーカプロセスを追加したり削除したりできます．</li><li>全てのプロセスはお互いに直接通信することができます．</li></ul><p>ワーカ間の接続（ビルトインのTCP/IP転送を利用）は，以下のような形で確立されます:</p><ul><li>マスタプロセス上で，<code>ClusterManager</code>とともに，<a href="../stdlib/Distributed.html#Distributed.addprocs"><code>addprocs</code></a>を呼び出します．</li><li><a href="../stdlib/Distributed.html#Distributed.addprocs"><code>addprocs</code></a>は適切な <a href="../stdlib/Distributed.html#Distributed.launch"><code>launch</code></a>を呼び，適切なマシン上で要求された数のワーカを生成します．</li><li>各ワーカはフリーなポートをリスンし始め，<a href="../base/io-network.html#Base.stdout"><code>stdout</code></a>にそのホストとポート情報を書き出します．</li><li>クラスタマネージャは各ワーカの <a href="../base/io-network.html#Base.stdout"><code>stdout</code></a>をキャプチャし，マスタプロセスで利用できるようにします．</li><li>マスタプロセ薄は個の情報をパース氏，各ワーカとのTCP/IP接続をセットアップします．</li><li>全てのワーカはクラスタ内の他のワーカにも通知されます．</li><li>各ワーカは自分自身の<code>id</code>よりも小さい<code>id</code>を持つ全てのワーカに接続します．</li><li>このようにして，メッシュネットワークが確立され，そこでは全てのワーカが全ての他のワーカと直接つなげられています．</li></ul><p>デフォルトのトランスポートレイヤは<a href="../stdlib/Sockets.html#Sockets.TCPSocket"><code>TCPSocket</code></a>を用いていますが，Juliaクラスタでは独自のトランスポートを 提供することができます．</p><p>Juliaは2つのビルトインなクラスタマネージャを提供します:</p><ul><li><a href="../stdlib/Distributed.html#Distributed.addprocs"><code>addprocs()</code></a>または<a href="../stdlib/Distributed.html#Distributed.addprocs"><code>addprocs(np::Integer)</code></a>が呼ばれたときに使用される<code>LocalManager</code></li><li><a href="../stdlib/Distributed.html#Distributed.addprocs"><code>addprocs(hostnames::Array)</code></a>がホストネームのリスト共に呼び出された時に使用される<code>SSHManager</code></li></ul><p><code>LocalManager</code>は同じホスト上でワーカを追加して起動するのに用いられ，それによりマルチコア，マルチプロセッサ なハードウェアを有効活用します．</p><p>Thus, a minimal cluster manager would need to: したがって，最小限のクラスタマネージャは以下のようである必要があります: </p><ul><li>アブストラクトな<code>ClusterManager</code>のサブタイプであること</li><li>新しいワーカを起動することを担当するメソッドである<a href="../stdlib/Distributed.html#Distributed.launch"><code>launch</code></a>を実装すること</li><li>ワーカのライフタイムの間の様々なイベント（例えば，割り込み信号の送信）の際に呼ばれる，<a href="../stdlib/Distributed.html#Distributed.manage"><code>manage</code></a>を実装すること</li></ul><p><a href="../stdlib/Distributed.html#Distributed.addprocs"><code>addprocs(manager::FooManager)</code></a>は<code>FooManager</code>が実装されていることを必要とします:</p><pre><code class="language-julia">function launch(manager::FooManager, params::Dict, launched::Array, c::Condition)
    [...]
end

function manage(manager::FooManager, id::Integer, config::WorkerConfig, op::Symbol)
    [...]
end</code></pre><p>例として，同じホスト上でワーカの起動を担当するマネージャである<code>LocalManager</code>がどのように実装されているかを見てみましょう:</p><pre><code class="language-julia">struct LocalManager &lt;: ClusterManager
    np::Integer
end

function launch(manager::LocalManager, params::Dict, launched::Array, c::Condition)
    [...]
end

function manage(manager::LocalManager, id::Integer, config::WorkerConfig, op::Symbol)
    [...]
end</code></pre><p><a href="../stdlib/Distributed.html#Distributed.launch"><code>launch</code></a>メソッドは以下のような引数を取ります:</p><ul><li><code>manager::ClusterManager</code>: <a href="../stdlib/Distributed.html#Distributed.addprocs"><code>addprocs</code></a>が呼び出されるクラスタマネージャ</li><li><code>params::Dict</code>: <a href="../stdlib/Distributed.html#Distributed.addprocs"><code>addprocs</code></a>に渡される全てのキーワード引数</li><li><code>launched::Array</code>: 1つ以上の<code>WorkerConfig</code>オブジェクトをアペンドするための配列</li><li><code>c::Condition</code>: ワーカの起動時に通知される条件変数</li></ul><p><a href="../stdlib/Distributed.html#Distributed.launch"><code>launch</code></a>メソッドは，別のタスクで非同期的に呼び出されます．このタスクの終了は， 要求された全てのワーカが起動されたことを示しています．したがって，要求された全てのワーカが 起動されたらすぐに，<a href="../stdlib/Distributed.html#Distributed.launch"><code>launch</code></a>関数は終了されなければなりません．</p><p>新たに起動されたワーカは，お互いとマスタプロセスにall-to-allに接続されます．コマンドライン引数<code>--worker[=&lt;cookie&gt;]</code> を指定すると，起動されたプロセスがワーカとして初期化され，TCP/IPソケットを介して接続がセットアップされます．</p><p>クラスタ内の全てのワーカはマスタと同じ<a href="distributed-computing.html#man-cluster-cookie">cookie</a>を共有します．クッキーが指定されていない場合， つまり<code>--worker</code>を指定した場合，ワーカはそれを標準入力から読み込もうとします． <code>LocalManager</code>と<code>SSHManager</code>はどちらも自らの標準入力を介して，新しく起動されたワーカにクッキーを渡します．</p><p>デフォルトではワーカは<a href="../stdlib/Sockets.html#Sockets.getipaddr"><code>getipaddr()</code></a>の呼び出しで返されたアドレスの空きポートをリスンします． リスンする特定のアドレスはオプションの引数<code>--bind-to bind_addr[:port]</code>で指定できます．これはマルチホームホストに便利です．</p><p>非TCP/IPトランスポートの例として，実装はMPIを使用することを選ぶことができるが，その場合は<code>--worker</code>は指定してはならない． 代わりに，新しく起動されたワーカは，並列構成を使う前に<code>init_worker(cookie)</code>を呼び出さねばなりません．</p><p>起動された全てのワーカに対して，<a href="../stdlib/Distributed.html#Distributed.launch"><code>launch</code></a>は<code>WorkerConfig</code>オブジェクトを（適切なフィールドを初期化しながら）<code>launched</code>に追加しなければなりません．</p><pre><code class="language-julia">mutable struct WorkerConfig
    # Common fields relevant to all cluster managers
    io::Union{IO, Nothing}
    host::Union{AbstractString, Nothing}
    port::Union{Integer, Nothing}

    # Used when launching additional workers at a host
    count::Union{Int, Symbol, Nothing}
    exename::Union{AbstractString, Cmd, Nothing}
    exeflags::Union{Cmd, Nothing}

    # External cluster managers can use this to store information at a per-worker level
    # Can be a dict if multiple fields need to be stored.
    userdata::Any

    # SSHManager / SSH tunnel connections to workers
    tunnel::Union{Bool, Nothing}
    bind_addr::Union{AbstractString, Nothing}
    sshflags::Union{Cmd, Nothing}
    max_parallel::Union{Integer, Nothing}

    # Used by Local/SSH managers
    connect_at::Any

    [...]
end</code></pre><p><code>WorkerConfig</code>のフィールドのほとんどは，ビルトインのマネージャで使用されます．カスタムクラスタマネージャは通常， <code>io</code>または<code>host</code> / <code>port</code>のみを指定します:</p><ul><li><code>io</code>が指定された場合，それはホスト/ポート情報を読み込むために使用されます．Juliaワーカは起動時にバインドアドレスとポートを出力します．これにより，ワーカのポートを手動で設定することを要求する代わりにJuliaワーカは空いている任意ポートをリスンすることができます．</li><li><code>io</code>が指定されていない場合，<code>host</code>と<code>port</code>が接続に用いられます．</li><li><code>count</code>，<code>exename</code>，および<code>exeflags</code>は，ワーカから追加のワーカを起動する際に関連します．例えばクラスタマネージャはノードごとに単一のワーカを起動し，それを使用して追加のワーカを起動することができます．<ul><li><code>count</code>に整数値<code>n</code>を指定すると合計<code>n</code>個のワーカが起動されます．</li><li><code>count</code>に<code>:auto</code>の値を指定すると，そのマシンのCPUスレッド（論理コア）の数と同じ数のワーカを起動します．</li><li><code>exename</code>はフルパスを含む<code>julia</code>実行ファイルの名前です．</li><li><code>exeflags</code>は新しいワーカに必要なコマンドライン引数に設定してください．</li></ul></li><li><code>tunnel</code>，<code>bind_addr</code>，<code>sshflags</code>および<code>max_parallel</code>はマスタプロセスからワーカに接続するためにsshトンネルが必要な場合に使用されます．</li><li><code>userdata</code>はカスタムクラスタマネージャが独自のワーカの固有の情報を保存するために提供されます．</li></ul><p><code>manage(manager::FooManager, id::Integer, config::WorkerConfig, op::Symbol)</code>は以下のような<code>op</code>値を指定して， ワーカのライフタイム中に異なるタイミングで呼び出されます: </p><ul><li>Juliaワーカプールでワーカが追加削除されたときに指定する<code>:register</code>/<code>:deregister</code></li><li><code>interrupt(workers)</code>が呼び出されたときに指定する<code>:interrupt</code>．<code>ClusterManager</code>は適切なワーカに対して，割り込み信号を送信しなければなりません．</li><li>クリーンアップのために指定する<code>:finalize</code>．</li></ul><h3 id="カスタムトランスポートを使用したクラスタマネージャ"><a class="docs-heading-anchor" href="#カスタムトランスポートを使用したクラスタマネージャ">カスタムトランスポートを使用したクラスタマネージャ</a><a id="カスタムトランスポートを使用したクラスタマネージャ-1"></a><a class="docs-heading-anchor-permalink" href="#カスタムトランスポートを使用したクラスタマネージャ" title="Permalink"></a></h3><p>デフォルトのTCP/IPのall-to-allなソケット接続をカスタムのトランスポートレイヤに置き換えるのはもう少し複雑です． 各Juliaプロセスは，接続されているワーカの数だけ通信タスクを持っています．例えば，32プロセスからなるJulia クラスタがall-to-allなメッシュネットワークにあるとします:</p><ul><li>各Juliaプロセスは31個の通信タスクを持っています．</li><li>各タスクは，メッセージ処理のループで単一のリモートワーカからの全ての着信メッセージを処理します．</li><li>The message-processing loop waits on an <code>IO</code> object (for example, a <a href="../stdlib/Sockets.html#Sockets.TCPSocket"><code>TCPSocket</code></a> in the default implementation), reads an entire message, processes it and waits for the next one.</li><li>メッセージ処理ループは，<code>IO</code>オブジェクト（例えば，デフォルトの実装では<a href="../stdlib/Sockets.html#Sockets.TCPSocket"><code>TCPSocket</code></a>）上で待機し，メッセージ全体を読み込んで処理し，次のメッセージを待ちます．</li><li>プロセスへのメッセージの送信は，通信タスクだけでなく，Juliaタスクからも，適切な<code>IO</code>オブジェクトを介して直接行われます．</li></ul><p>デフォルトのトランスポートを置き換えるには，新しい実装でリモートワーカへの接続を設定し，メッセージ処理ループが 待機できる適切な<code>IO</code>オブジェクトを提供する必要があります．マネージャ固有のコールバックは以下の通り実装されます:</p><pre><code class="language-julia">connect(manager::FooManager, pid::Integer, config::WorkerConfig)
kill(manager::FooManager, pid::Int, config::WorkerConfig)</code></pre><p>デフォルトの実装（TCP/IPソケットを使用）は，<code>connect(manager::ClusterManager, pid::Integer, config::WorkerConfig)</code>として実装されています．</p><p><code>connect</code>はワーカ<code>pid</code>から送信されたデータを読み込むための<code>IO</code>オブジェクトと，ワーカ<code>pid</code>に送信する必要が あるデータを書き込むための<code>IO</code>オブジェクトのペアを返す必要があります．カスタムクラスタマネージャは， カスタマイズされたおそらく<code>IO</code>ではないトランスポートと，Juliaのビルトインな並列インフラストラクチャの間で， データをプロキシするための配管として，インメモリの<code>BufferStream</code>を使用することができます．</p><p><code>BufferStream</code>はインメモリの<a href="../base/io-network.html#Base.IOBuffer"><code>IOBuffer</code></a>で，<code>IO</code>のように振舞います，すなわち非同期に処理できるストリームです．</p><p><a href="https://github.com/JuliaAttic/Examples">Examples repository</a>レポジトリの<code>clustermanager/0mq</code>フォルダには， ZeroMQを利用して0MQブローカを中央に配置したスター型のトポロジでJuliaワーカを接続する例があります． 注意: Juliaプロセスは全て，まだ<em>論理的</em>に接続されています，つまりどのワーカもトランスポートレイヤとして使用されている 0MQを意識することなく，他のワーカに直接メッセージを送ることができます．</p><p>When using custom transports: カスタムトランスポートを使用する場合は:</p><ul><li>Juliaワーカは<code>--worker</code>で開始してはなりません．<code>--worker</code>をつけて起動すると，新しく起動されたワーカはTCP/IPソケットトランスポートの実装をデフォルトにします．</li><li>ワーカとの論理接続を受信するたびに，<code>Base.process_messages(rd::IO, wr::IO)()</code>が呼び出されなければなりません．これは<code>IO</code>オブジェクトであらわされるワーカとの間のメッセージの読み書きを処理する新しいタスクを起動します．</li><li><code>init_worker(cookie, manager::FooManager)</code>はワーカプロセスの初期化の一部として呼び出されなければなりません．</li><li><code>WorkerConfig</code>の中の<code>connect_at::Any</code>フィールドは，<a href="../stdlib/Distributed.html#Distributed.launch"><code>launch</code></a>が呼ばれた時にクラスタマネージャによって設定することができます．このフィールドの値は全ての<a href="../stdlib/Distributed.html#Sockets.connect-Tuple{ClusterManager,Int64,WorkerConfig}"><code>connect</code></a>コールバックで渡されます．通常，このフィールドはワーカへの接続方法に関する情報を保持します．例えば，TCP/IPソケットトランスポートはこのフィールドを利用して，ワーカに接続するための<code>(host, port)</code>タプルを指定します．</li></ul><p><code>kill(manager, pid, config)</code>はクラスタからワーカを削除するために呼び出されます．マスタプロセス上では， 適切なクリーンアップを確実にするために，対応する<code>IO</code>オブジェクトは実装によってクローズされなければなりません． デフォルトの実装では，指定されたリモートワーカに対して，<code>exit()</code>を実行するだけです．</p><p>Examplesフォルダの<code>clustermanager/simple</code>は，クラスタのセットアップにUNIXドメインソケットを使用した簡単な実装を示す例です．</p><h3 id="LocalManagerとSSHManagerのネットワーク要件"><a class="docs-heading-anchor" href="#LocalManagerとSSHManagerのネットワーク要件">LocalManagerとSSHManagerのネットワーク要件</a><a id="LocalManagerとSSHManagerのネットワーク要件-1"></a><a class="docs-heading-anchor-permalink" href="#LocalManagerとSSHManagerのネットワーク要件" title="Permalink"></a></h3><p>Juliaクラスタはローカルのラップトップ，部署のクラスタ，クラウドといった，インフラストラクチャ上にすでに セキュアにされている環境下で実行されるように設計されています．このセクションでは，ビルトインである <code>LocalManager</code>と<code>SSHManager</code>のネットワークセキュリティ要件について説明します:</p><ul><li><p>マスタプロセスはどのポートもリスンせず，ワーカに対して外向きにのみ接続します．</p></li><li><p>各ワーカはローカルインタフェースの1つだけにバインドし，OSによって割り当てられた，エフェメラルなポート番号でリスンします．</p></li><li><p><code>addprocs(N)</code>が使用する<code>LocalManager</code>は，デフォルトでは，ループバックインタフェースにのみバインドします．これはあとからリモートホスト上で起動されたワーカが（あるいは悪意のある者によって起動されたものが）クラスタに接続できないことを意味します．<code>addprocs([&quot;remote_host&quot;])</code>の後に<code>addprocs(4)</code>を実行しても失敗します．ユーザによってはローカルシステムといくつかのリモートシステムからなるクラスタを作成する必要があるかもしれません．これは外部ネットワークインタフェースをバインドするように，キーワード引数<code>restrict</code>を<code>addprocs(4; restrict=false)</code>と設定しながら，明示的に<code>LocalManager</code>に要求することで行うことができます．</p></li><li><p><code>addprocs(list_of_remote_hosts)</code>によって使用される<code>SSHManager</code>は，SSH経由でリモートホスト上のワーカを起動します．デフォルトでは，SSHはJuliaのワーカを起動するためのみに使用されます．その後のマスタ-ワーカ間およびワーカ-ワーカ間の接続では，プレーンで暗号化されていないTCP/IPソケットを使用します．リモートホストはパスワードなしのログインが有効になっている必要があります．追加のSSHフラグや認証情報は，キーワード引数<code>sshflags</code>で指定できます．</p></li><li><p><code>addprocs(list_of_remote_hosts; tunnel=true, sshflags=&lt;ssh keys and other flags&gt;)</code>はマスタ-ワーカ間にもSSH接続を使用したい場合に便利です．典型的なシナリオは，Julia REPL（すなわちマスタ）を実行しているローカルのラップトップと，クラウド上のクラスタの残りの部分，例えばAmazon EC2上のものですが，それらが一緒に動いているような場合です．この場合，公開鍵インフラストラクチャ(PKI)を介して認証されたSSHクライアントと組み合わせてリモートクラスタでポート22を開く必要があるだけです．認証のための認証情報は，<code>sshflags</code>を使って，例えば<code>sshflags=`-i &lt;keyfile&gt;`</code>のようにして提供することができます．</p><p>all-to-allなトポロジ（デフォルト）では，全てのワーカはプレーンなTCPソケットを介して互いに接続します．したがって，クラスタノードのセキュリティポリシは，(OSによって異なりますが）エフェメラルポート範囲のワーカ間の自由な接続を保証する必要があります．</p><p>全てのワーカ-ワーカ間のトラフィックをSSH経由でセキュアにして暗号化したり，個々のメッセージを暗号化したりすることは，カスタム<code>ClusterManager</code>を介して行うことができます．</p></li><li><p><code>addprocs</code>のオプションとして<code>multiplex=true</code>を指定した場合，SSH多重化はマスタとワーカの間にトンネルを作成するために使用されます．独自にSSH多重化を設定しており，接続が既に確立されている場合は，<code>multiplex</code>オプションに関係なく，SSH多重化が使用されます．多重化が有効になっている場合は，既存の接続を使用して転送が設定されます（sshの<code>-O forward</code>オプション）．これは，サーバがパスワード認証を必要とするときに有効です．: <code>addprocs</code>の前にサーバにログインすることで，Juliaでの認証を回避することができます．既存の多重化接続が使用されていない限り，セッションの間制御ソケットは，<code>~/.ssh/julia-%r@%h:%p</code>に置かれます．ノード上に複数のプロセスを作成して多重化を有効にすると，帯域幅が制限される可能性があることに注意してください，なぜならこの場合，プロセスは単一の多重化TCP接続を共有するからです．</p></li></ul><h3 id="man-cluster-cookie"><a class="docs-heading-anchor" href="#man-cluster-cookie">Cluster Cookie</a><a id="man-cluster-cookie-1"></a><a class="docs-heading-anchor-permalink" href="#man-cluster-cookie" title="Permalink"></a></h3><p>クラスタ内の全てのプロセスは同じクッキーを共有しますが，これはデフォルトでは，マスタプロセス上でランダムに生成された文字列です:</p><ul><li><a href="../stdlib/Distributed.html#Distributed.cluster_cookie-Tuple{}"><code>cluster_cookie()</code></a>はクッキーを返し，<code>cluster_cookie(cookie)()</code>はクッキーを設定して新しいクッキーを返します．</li><li>全ての接続は双方で認証され，マスタによって起動されたワーカだけがお互いに接続を許可されることを確実にします．</li><li>クッキーは引数<code>--worker=&lt;cookie&gt;</code>で起動時にワーカに渡すことができます．<code>--worker</code>がクッキーなしで指定された場合，ワーカは標準入力（<a href="../base/io-network.html#Base.stdin"><code>stdin</code></a>）からクッキーを読み込もうとします．<code>stdin</code>はクッキーが取得された直後に閉じられます．</li><li><code>ClusterManager</code>sは，<a href="../stdlib/Distributed.html#Distributed.cluster_cookie-Tuple{}"><code>cluster_cookie()</code></a>を呼び出すことでマスタ上のクッキーを取得できます．デフォルトのTCP/IPトランスポートを使用していない（つまり，<code>--worker</code>を指定していない）クラスタマネージャは，マスタ上のものと同じクッキーで<code>init_worker(cookie, manager)</code>を呼び出さなければなりません．</li></ul><p>より高いレベルのセキュリティを必要とする環境では，カスタムの<code>ClusterManager</code>を通してこれを実装できることに注意してください． 例えば，クッキーは事前に共有することができ，それゆえに起動時の引数として指定されません．</p><h2 id="ネットワークトポロジの指定-(Experimental)"><a class="docs-heading-anchor" href="#ネットワークトポロジの指定-(Experimental)">ネットワークトポロジの指定 (Experimental)</a><a id="ネットワークトポロジの指定-(Experimental)-1"></a><a class="docs-heading-anchor-permalink" href="#ネットワークトポロジの指定-(Experimental)" title="Permalink"></a></h2><p>The keyword argument <code>topology</code> passed to <code>addprocs</code> is used to specify how the workers must be connected to each other: <code>addprocs</code>に渡されるキーワード引数<code>topology</code>は，ワーカがどのように相互に接続されなければならないかを指定するために使用されます:</p><ul><li><code>:all_to_all</code>，デフォルト: 全てのワーカが相互に接続されます．</li><li><code>:master_worker</code>: ドライバプロセス，すなわち<code>pid</code>1のもののみがワーカに対して接続します．</li><li><code>:custom</code>: クラスタマネージャの<code>launch</code>方法は<code>WorkerConfig</code>の<code>ident</code>フィールドと<code>connect_idents</code>フィールドで接続トポロジを指定します．クラスタマネージャが提供するアイデンティティ<code>ident</code>を持つワーカは，<code>connect_idents</code>で指定された全てのワーカに接続します．</li></ul><p>キーワード引数<code>lazy=true|false</code>は<code>topology</code>オプションの<code>:all_to_all</code>のみに影響します．<code>true</code>に設定されている場合， クラスタはマスタが全てのワーカに接続された状態で開始します．特定のワーカ-ワーカ間の接続は2つのワーカ間の最初の リモート呼び出し時に確立されます．これにより，クラスタ内通信に割り当てられる初期リソースを削減するのに役立ちます． 接続は並列プログラムのランタイム要件に応じて設定されます．<code>lazy</code>のデフォルト値は<code>true</code>です．</p><p>現在，接続されていないワーカ間でメッセージを送信するとエラーになります．この動作は，機能やインタフェースと 同様に，実験的なものであり，将来のリリースで変更される可能性があります．</p><h2 id="注目すべき外部パッケージ"><a class="docs-heading-anchor" href="#注目すべき外部パッケージ">注目すべき外部パッケージ</a><a id="注目すべき外部パッケージ-1"></a><a class="docs-heading-anchor-permalink" href="#注目すべき外部パッケージ" title="Permalink"></a></h2><p>Juliaの並列化以外にも，言及すべき外部パッケージはたくさんあります．例えば，<a href="https://github.com/JuliaParallel/MPI.jl">MPI.jl</a> は<code>MPI</code>プロトコルのJuliaラッパであり，<a href="https://github.com/JuliaParallel/Distributedarrays.jl">DistributedArrays.jl</a>は <a href="../stdlib/SharedArrays.html#Shared-Arrays">Shared Arrays</a>で紹介した通りです．またJuliaのGPUプログラミングエコシステムについても言及しなければなりません:</p><ol><li><p>低レベル（Cカーネル）ベースの操作<a href="https://github.com/JuliaGPU/OpenCL.jl">OpenCL.jl</a>と<a href="https://github.com/JuliaGPU/CUDAdrv.jl">CUDAdrv.jl</a>はそれぞれ，OpenCLインタフェースとCUDAラッパです．</p></li><li><p><a href="https://github.com/JuliaGPU/CUDAnative.jl">CUDAnative.jl</a>のような低レベル（Juliaカーネル）インタフェースは，JuliaネイティブなCUDA実装です．</p></li><li><p><a href="https://github.com/JuliaGPU/CuArrays.jl">CuArrays.jl</a>や<a href="https://github.com/JuliaGPU/CLArrays.jl">CLArrays.jl</a>のような高レベルのベンダ固有の抽象化</p></li><li><p><a href="https://github.com/JuliaComputing/ArrayFire.jl">ArrayFire.jl</a>や<a href="https://github.com/JuliaGPU/GPUArrays.jl">GPUArrays.jl</a>のような高レベルのライブラリ</p></li></ol><p>以下の例では，<code>DistributedArrays.jl</code>と<code>CuArrays.jl</code>の両方を使用して，最初に<code>distribute()</code>と<code>CuArray()</code>を通して配列をキャスト することで，複数のプロセスに配列を分散させます．</p><p><code>DistributedArrays.jl</code>を全てのプロセスにわたってインポートする時には，<a href="../stdlib/Distributed.html#Distributed.@everywhere"><code>@everywhere</code></a>を使用することを忘れないでください</p><pre><code class="language-julia-repl">$ ./julia -p 4

julia&gt; addprocs()

julia&gt; @everywhere using DistributedArrays

julia&gt; using CuArrays

julia&gt; B = ones(10_000) ./ 2;

julia&gt; A = ones(10_000) .* π;

julia&gt; C = 2 .* A ./ B;

julia&gt; all(C .≈ 4*π)
true

julia&gt; typeof(C)
Array{Float64,1}

julia&gt; dB = distribute(B);

julia&gt; dA = distribute(A);

julia&gt; dC = 2 .* dA ./ dB;

julia&gt; all(dC .≈ 4*π)
true

julia&gt; typeof(dC)
DistributedArrays.DArray{Float64,1,Array{Float64,1}}

julia&gt; cuB = CuArray(B);

julia&gt; cuA = CuArray(A);

julia&gt; cuC = 2 .* cuA ./ cuB;

julia&gt; all(cuC .≈ 4*π);
true

julia&gt; typeof(cuC)
CuArray{Float64,1}</code></pre><p>いくつかのJuliaの昨日は現在CUDAnative.jl<sup class="footnote-reference"><a id="citeref-2" href="#footnote-2">[2]</a></sup>ではサポートされていないことに注意してください．特に<code>sin</code>のような関数は，<code>CUDAnative.sin</code>(cc: @maleadt)で置き換える必要があります．</p><p>次の例では，<code>DistributedArrays.jl</code>と<code>CuArrays.jl</code>の両方を使って，複数のプロセスに配列を分散させ，その上で汎用関数を呼び出すようにします．</p><pre><code class="language-julia">function power_method(M, v)
    for i in 1:100
        v = M*v
        v /= norm(v)
    end

    return v, norm(M*v) / norm(v)  # or  (M*v) ./ v
end</code></pre><p><code>power_method</code>は新しいベクトルの生成と正規化を繰り返しています．関数宣言では型の指定をしていませんでしたが， 前述のデータ型で動作するかを見てみましょう: </p><pre><code class="language-julia-repl">julia&gt; M = [2. 1; 1 1];

julia&gt; v = rand(2)
2-element Array{Float64,1}:
0.40395
0.445877

julia&gt; power_method(M,v)
([0.850651, 0.525731], 2.618033988749895)

julia&gt; cuM = CuArray(M);

julia&gt; cuv = CuArray(v);

julia&gt; curesult = power_method(cuM, cuv);

julia&gt; typeof(curesult)
CuArray{Float64,1}

julia&gt; dM = distribute(M);

julia&gt; dv = distribute(v);

julia&gt; dC = power_method(dM, dv);

julia&gt; typeof(dC)
Tuple{DistributedArrays.DArray{Float64,1,Array{Float64,1}},Float64}</code></pre><p>外部パッケージの簡単な紹介の最後として，MPIプロトコルのJuliaラッパである<code>MPI.jl</code>について考えてみましょう． 全ての内部関数を考慮するには時間がかかりすぎるので，プロトコルを実装するために使用されているアプローチを 単純に評価する方が良いでしょう．</p><p>単純に各サブプロセスを呼び出し，そのランクをインスタンス化し，マスタプロセスに到達したらランクの合計を計算する， このおもちゃのスクリプトを考えてみましょう</p><pre><code class="language-julia">import MPI

MPI.Init()

comm = MPI.COMM_WORLD
MPI.Barrier(comm)

root = 0
r = MPI.Comm_rank(comm)

sr = MPI.Reduce(r, MPI.SUM, root, comm)

if(MPI.Comm_rank(comm) == root)
   @printf(&quot;sum of ranks: %s\n&quot;, sr)
end

MPI.Finalize()</code></pre><pre><code class="language-none">mpirun -np 4 ./julia example.jl</code></pre><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>MPIはこの文脈ではMPI-1標準を指しています．MPI-2以降，MPI標準化委員会は，リモートメモリアクセス(RMA)と総称される新しい通信メカニズムのセットを導入しました．MPI標準にrmaを追加した動機は，一方向的な通信パターンを容易にすることでした．最新のMPI企画についての詳細は，<a href="https://mpi-forum.org/docs">https://mpi-forum.org/docs</a>を参照してください．</li><li class="footnote" id="footnote-2"><a class="tag is-link" href="#citeref-2">2</a><a href="http://juliagpu.github.io/CUDAnative.jl/stable/man/usage.html#Julia-support-1">Julia GPU man pages</a></li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="multi-threading.html">« Multi-Threading</a><a class="docs-footer-nextpage" href="running-external-programs.html">外部プログラムの実行 »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Monday 15 February 2021 22:42">Monday 15 February 2021</span>. Using Julia version 1.5.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
